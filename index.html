<!DOCTYPE html>
<html lang="en">
<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>NLV: Natural Language Utterances for Specifying Data Visualizations</title>

  <!-- CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z" crossorigin="anonymous">
  <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.10.0/css/all.css" integrity="sha384-AYmEC3Yw5cVb3ZcuHtOA93w35dYTsvhLPVnYs9eStHfGJvOvKxVfELGroGkvsg+p" crossorigin="anonymous"/>
  <link href="css/style.css" rel="stylesheet">

  <!-- JavaScript -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.bundle.min.js" integrity="sha384-LtrjvnR4Twt/qOuYxE721u19sVFLVSA4hf/rRt6PrZTmiPltdZcI7q7PXQBYTKyf" crossorigin="anonymous"></script>  

</head>

<body>

<!-- Navigation -->
<nav id="pageHeader" class="navbar navbar-expand-lg navbar-dark">
  <div class="container">
    <h3>NLV: Natural Language Utterances for Specifying Data Visualizations</h3>
    <h5><a id="githubLink" href="https://github.com/nlvcorpus/nlvcorpus.github.io"><i class="fab fa-github"></i> View on GitHub</a></h5>
  </div>
</nav>

<!-- Page Content -->
<div id="mainBody" class="container">
  <div class="row">
    <div class="col-md-9">
      <p>
        Natural language interfaces (NLIs) for data visualization are becoming increasingly popular both in academic research and in commercial software. Yet, there is a lack of empirical understanding of how people specify visualizations through natural language. To bridge this gap, we conducted an online study with 102 participants. We showed participants a series of ten visualizations for a given dataset and asked them to provide utterances they would pose to generate the displayed charts. The curated list of utterances generated from the study is provided below. This corpus of utterances can be used to evaluate existing NLIs for data visualization as well as for creating new systems and models to generate visualizations from natural language utterances.
      </p>
      <p>
        For more details about the study, corpus, and potential applications, please refer to the accompanying <a href="paper-chi21.pdf" target="blank"><i class="fa fa-file-pdf"></i> research paper</a>.
      </p>
    </div>
    <div id="authorList" class="col-md-3" align="left">
      <h5><u>Team</u></h5>
      <a href="https://arjun010.github.io" target="blank">Arjun Srinivasan</a><span style="font-size: small;">, Georgia Tech</span>
      <br><a href="https://nikhilanyapathy.com" target="blank">Nikhila Nyapathy</a><span style="font-size: small;">, Georgia Tech</span>
      <br><a href="https://www.microsoft.com/en-us/research/people/bongshin/" target="blank">Bongshin Lee</a><span style="font-size: small;">, Microsoft Research</span>
      <br><a href="https://www.microsoft.com/en-us/research/people/sdrucker/" target="blank">Steven M. Drucker</a><span style="font-size: small;">, Microsoft Research</span>
      <br><a href="https://www.cc.gatech.edu/~john.stasko/" target="blank">John Stasko</a><span style="font-size: small;">, Georgia Tech</span>
      <br><br>
      <img src="https://brand.gatech.edu/sites/default/files/2020-08/gt-logo-gold.png" height="40px">
      <img src="https://suitabletech.com/images/stories/Case_Studies/Microsoft_logo.png" height="30px">
    </div>
  </div>
  
  <hr/>
  <div>
    <h5><i class="fa fa-table"></i> Corpus (Link to <a href="https://docs.google.com/spreadsheets/d/1GMWktNGJCwC8U1dvT0gMggVRRYqN3uL28zjVDbxYJOg/edit?usp=sharing" target="blank">Google Sheet</a>)</h5>
    <div style="width: 100%;height: 355px;">
      <iframe id="datasetPreview" src="https://docs.google.com/spreadsheets/d/e/2PACX-1vTDiLB5fbVTQjlN3qZGQTFn2wfXxvrqmN8P71xtEIVWNcwF6LRrBRPM8eiD_zjMBOZSC6jabgbsU0NE/pubhtml?gid=0&amp;single=true&amp;widget=true&amp;headers=false" width="100%" height="100%"></iframe>
    </div>
    <br>
    <p>
      The above table displays <b>814 utterance sets</b> curated from the <a href="https://arjun010.github.io/nlstudy/" target="blank">online study</a>. Here, we define an utterance set as a collection of one or more utterances that collectively map to a specific visualization. Utterance sets can be singletons (i.e., contain a single utterance) or sequential (i.e., composed of two or more utterances).
    </p>
    <p>
      Column descriptions:
      <ul>
        <li><b>sequential</b>: Indicates if an utterance set is singleton ('n') or sequential ('y'). Individual utterances in sequential utterance sets are separated by a pipe symbol (|).</li>
        <li><b>visId</b>: The type of visualization an utterance set maps to. The study presented ten visualizations during each session. Vega-Lite specifications corresponding to different visIds can be found in the <a href="https://github.com/nlvcorpus/nlvcorpus.github.io/blob/main/vlSpecs.json" target="blank">vlSpecs.json</a> file on the GitHub repo. All visualizations used during the study can also be viewed on a single page <a href="/vizes.html" target="blank">here</a>.</li>
        <li><b>dataset</b>: The dataset an utterance set was issued in the context of. The <a href="https://github.com/nlvcorpus/nlvcorpus.github.io/tree/main/datasets" target="blank">three datasets used during the study</a> can be found on the GitHub repo.</li>
      </ul>    
    </p>
  </div>
</div>

<div class="footer" align="middle">
  <b>LICENSE</b>
  <br>This corpus is freely available for use under the <a href="https://github.com/nlvcorpus/nlvcorpus.github.io/blob/main/LICENSE" target="blank">MIT License</a> terms.
</div>

</body>
</html>